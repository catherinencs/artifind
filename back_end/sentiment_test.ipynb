{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from search import SearchEngine\n",
    "from article import ArticleParser\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    text_blob_object = TextBlob(text)\n",
    "    return text_blob_object.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_search_url_time(\n",
    "    search_term: str,\n",
    "    start: datetime,\n",
    "    end: datetime):\n",
    "    \"\"\"\n",
    "    Generates a search URL for the given search term and start and end date\n",
    "    Used for sentiment analysis over time\n",
    "    \"\"\"\n",
    "    if start and not end:\n",
    "        # no to date, default to a timeframe of 10 days\n",
    "        end = start + timedelta(days=10)\n",
    "    elif end and not start:\n",
    "        # no from date, default to a timeframe of 10 days\n",
    "        start = end - timedelta(days=10)\n",
    "    elif not end and not start:\n",
    "        # neither exist, default to a timeframe of the past 10 days\n",
    "        end = datetime.today()\n",
    "        start = end - timedelta(days=10)\n",
    "\n",
    "    delta = end - start\n",
    "\n",
    "    # for every day in the range, generate a search URL for the same topic\n",
    "\n",
    "    # specifying \"pointers\" to the start and end date\n",
    "    from_date = start\n",
    "    to_date = start + timedelta(days=1)\n",
    "\n",
    "    urls = []\n",
    "\n",
    "    for _ in range(delta.days):\n",
    "        time_filter = f'after:{from_date.strftime(\"%Y-%m-%d\")} before:{to_date.strftime(\"%Y-%m-%d\")}'\n",
    "        urls.append(f'https://news.google.com/rss/search?q={search_term}+{time_filter}&hl=en-US&gl=US&ceid=US:en')\n",
    "        from_date = to_date\n",
    "        to_date = to_date + timedelta(days=1)\n",
    "\n",
    "    for d in urls:\n",
    "        print(d)\n",
    "\n",
    "    # time_filter = f'after:{from_date.strftime(\"%Y-%m-%d\")} before:{to_date.strftime(\"%Y-%m-%d\")}'\n",
    "    # url = f'https://news.google.com/rss/search?q={search_term}+{time_filter}&hl=en-US&gl=US&ceid=US:en'\n",
    "\n",
    "    # return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.google.com/rss/search?q=balls+after:2023-07-07 before:2023-07-08&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-08 before:2023-07-09&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-09 before:2023-07-10&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-10 before:2023-07-11&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-11 before:2023-07-12&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-12 before:2023-07-13&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-13 before:2023-07-14&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-14 before:2023-07-15&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-15 before:2023-07-16&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-16 before:2023-07-17&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-17 before:2023-07-18&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-18 before:2023-07-19&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-19 before:2023-07-20&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-20 before:2023-07-21&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-21 before:2023-07-22&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-22 before:2023-07-23&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-23 before:2023-07-24&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-24 before:2023-07-25&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-25 before:2023-07-26&hl=en-US&gl=US&ceid=US:en\n",
      "https://news.google.com/rss/search?q=balls+after:2023-07-26 before:2023-07-27&hl=en-US&gl=US&ceid=US:en\n"
     ]
    }
   ],
   "source": [
    "generate_search_url_time(\"balls\", datetime.today() - timedelta(days=20), datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate a * b search URLS for a given search term, a being the number of days we span over, and b being the number of articles per day. 2. perform sentment analysis for all articles. 3. average out sentiment for each day in the period. 4. plot a graph that shows the progression of sentiment over time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
